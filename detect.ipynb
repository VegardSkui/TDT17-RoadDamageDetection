{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "COLORS = [\"blue\", \"orange\", \"green\", \"red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov7 && \\\n",
    "    python detect.py \\\n",
    "        --device 1 \\\n",
    "        --weights runs/train/w6-nitti-p6-1856/weights/epoch_174.pt \\\n",
    "        --source ../data/derived/test-ll-1856/ \\\n",
    "        --save-txt \\\n",
    "        --nosave \\\n",
    "        --name w6-nitti-p6-1856-e174 \\\n",
    "        --save-conf \\\n",
    "        --no-trace \\\n",
    "        --augment \\\n",
    "        --iou-thres 1.0 \\\n",
    "        --conf 0.2 \\\n",
    "        --img-size 1856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output-cropped-test.csv\", \"w\") as fp:\n",
    "    c = 0\n",
    "    for path in tqdm.tqdm(sorted(pathlib.Path(\"./data/original/Norway/test/images\").glob(\"*.jpg\"))):\n",
    "        # Get the name of the image by removing the .jpg extension\n",
    "        name = path.name[:-4]\n",
    "\n",
    "        # Get the width and height of the original image\n",
    "        with Image.open(path) as image:\n",
    "            width, height = image.width, image.height\n",
    "\n",
    "        detections_path = pathlib.Path(f\"./yolov7/runs/detect/w6-nitti-p6-1856-e174/labels/{name}.txt\")\n",
    "        fp.write(f\"{name}.jpg,\")\n",
    "        detections = None\n",
    "        if detections_path.exists():\n",
    "            detections = np.loadtxt(detections_path, ndmin=2)\n",
    "\n",
    "            # Keep only detections above the given confidence threshold\n",
    "            detections = detections[detections[:, 5] > 0.6]\n",
    "\n",
    "            # Map the x-center and y-center coordinates relative to the image\n",
    "            detections[:, 1] *= 1856\n",
    "            detections[:, 2] = detections[:, 2] * 1856 + (height - 1856)\n",
    "\n",
    "            # Map width and height\n",
    "            detections[:, 3] *= 1856 / 2\n",
    "            detections[:, 4] *= 1856 / 2\n",
    "\n",
    "            # Get boxes in x1,y1,x2,y2-format from the x_center,y_center,half_width,half_height\n",
    "            boxes = np.column_stack([\n",
    "                detections[:, 1] - detections[:, 3],\n",
    "                detections[:, 2] - detections[:, 4],\n",
    "                detections[:, 1] + detections[:, 3],\n",
    "                detections[:, 2] + detections[:, 4],\n",
    "            ])\n",
    "\n",
    "            # Find the indices of the top 5 boxes per class using NMS with a given threshold\n",
    "            indices = []\n",
    "            for cl in range(4):\n",
    "                class_indicies = np.argwhere(detections[:, 0] == cl).flatten()\n",
    "                a = torchvision.ops.nms(\n",
    "                    torch.from_numpy(boxes[class_indicies]),\n",
    "                    torch.from_numpy(detections[class_indicies][:, 5]),\n",
    "                    0.45\n",
    "                ).numpy()[:5]\n",
    "                indices.extend(class_indicies[a])\n",
    "\n",
    "            # Order the remaining indices by decreasing confidence and keep only the top 5\n",
    "            indices = np.array(indices, dtype=np.int64)[np.argsort(-detections[indices, 5])][:5]\n",
    "\n",
    "            boxes = boxes.astype(int)\n",
    "            box_strings = []\n",
    "            for idx in indices:\n",
    "                box = boxes[idx]\n",
    "                box_strings.append(f\"{int(detections[idx, 0]) + 1} {box[0]} {box[1]} {box[2]} {box[3]}\")\n",
    "            fp.write(\" \".join(box_strings))\n",
    "        fp.write(\"\\n\")\n",
    "\n",
    "        # with Image.open(pathlib.Path(f\"./data/original/Norway/test/images/{name}.jpg\")) as image:\n",
    "        #     if detections is not None:\n",
    "        #         draw = ImageDraw.Draw(image)\n",
    "        #         for idx in indices:\n",
    "        #             xmin, ymin, xmax, ymax = boxes[idx]\n",
    "        #             draw.rectangle((xmin, ymin, xmax, ymax), fill=None, outline=COLORS[int(detections[idx, 0])], width=4)\n",
    "        #     image.save(f\"out/output-detection-{name}.jpg\")\n",
    "        #     c += 1\n",
    "        #     if c > 10:\n",
    "        #         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46c16811754cac753cd90599e201f72154c03058fe5b55cf645d537f190245a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
